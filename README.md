# Reproducibility Report of "Deep, complex, invertible networks for inversion of transmission effects in multimode optical fibres"

This repository is the official implementation of [Deep, complex, invertible networks for inversion of transmission effects in multimode optical fibres](https://papers.nips.cc/paper/2018/hash/148510031349642de5ca0c544f31b2ef-Abstract.html), by OisÃ­n Moran et al. The goal in the original paper was to build a complex neural network that can mimic the physics of a multi-mode fibre and restore the distorted images. When an image is sent through a multi-mode fibre, it will get distorted into a speckle image that is unrecognizable by human eyes. However, conventional methods to restore the images requires many optical instruments. Therefore, a neural network can greatly save time and complexity in restoring these speckle images.

First, here is what a motion picture looks like before and after transmitting through the multi-mode fibre, as well as the speckle image generated by the fibre:

<table>
<tr>
  <td align="center">Before</td>
  <td align="center">Speckle</td>
  <td align="center">After</td>
</tr>
  <tr>
    <td align="center"><img src=/Reproducibility_report/gifs/orig_punc.gif width="200" height="200"></td>
    <td align="center"><img src=/Reproducibility_report/gifs/1m_112x112_punc_speckles.gif width="200" height="200"></td>
    <td align="center"><img src=/Reproducibility_report/gifs/punc_Complex_L2_reg_epoch_300_lamb_0.03.gif width="200" height="200"></td>
  </tr>
</table>

>This motion picture was not included in the training or validation sets, which shows that the network generalized very well after training.

## Model Description

Here is a quick overview of the models we recreated from the original paper and used in this reproducibility report:

<table>
<tr>
  <td align="center">Forward model</td>
  <td align="center">Inverse model</td>
  <td align="center">Multi-res model</td>
</tr>
  <tr>
    <td align="center"><img src=/Reproducibility_report/figures/Forward_model.PNG></td>
    <td align="center"><img src=/Reproducibility_report/figures/Inverse_model_updated.PNG></td>
    <td align="center"><img src=/Reproducibility_report/figures/multi-res.PNG></td>
  </tr>
</table>

## Requirements

Main packages used to run our models in the reproducibility report:

```
CUDA 11.3.1
PyTorch 1.10.0
```
Hardware requirements:

<ul>
  <li>An NVIDIA GPU that supports CUDA 11.3.1 (we used a single RTX 3080 Ti)</li>
  <li>32 GB of system memory</li>
</ul>

## Training

All models were divided into four notebooks:
<ul>
  <li>Final_Paper_Pytorch_With_Comments_V1.ipynb</li>
  <li>Final_Paper_Pytorch_With_Comments_V1_part1.ipynb</li>
  <li>Final_Paper_Pytorch_With_Comments_V1_part1_relu.ipynb</li>
  <li>Final_Paper_Pytorch_With_Comments_V2_part1.ipynb</li>  
</ul>

The first notebook contains all the models, all with 300 epochs. Second notebook only contains the six models with different regularizations, and all with 600 epochs. Third notebook only contains the six models again, but with ReLU activations and 300 epochs. Four notebook only contains the same six models but with 1000 epochs.

>Each notebook will take anywhere between 3 to 6 hours to complete.

## Results

Our model achieves the following performance on :

### [Image Classification on ImageNet](https://paperswithcode.com/sota/image-classification-on-imagenet)

| Model name         | Top 1 Accuracy  | Top 5 Accuracy |
| ------------------ |---------------- | -------------- |
| My awesome model   |     85%         |      95%       |

>ðŸ“‹  Include a table of results from your paper, and link back to the leaderboard for clarity and context. If your main result is a figure, include that figure and link to the command or notebook to reproduce it.


## Contributing
Ahmed Khaled, Zhimu Guo   \
Department of Physics, Engineering Physics, and Astronomy  \
Queen's University  \
Kingston, ON K7L 3N6
